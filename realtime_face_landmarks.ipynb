{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import face_recognition\n",
                "from PIL import Image, ImageDraw\n",
                "import cv2\n",
                "import numpy as np"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "# capture the video from the camera\n",
                "webcam_video_stream = cv2.VideoCapture(0)\n",
                "webcam_video_stream.set(3,640)\n",
                "webcam_video_stream.set(4,320)\n",
                "all_face_locations = []"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "while True:\n",
                "    ret, current_frame = webcam_video_stream.read()\n",
                "    # current_frame_small = cv2.resize(current_frame, (0,0), fx=0.25, fy=0.25)\n",
                "\n",
                "    # find all facial landmarks in all the faces in the image\n",
                "    face_landmarks_list = face_recognition.face_landmarks(current_frame)\n",
                "\n",
                "    # convert the numpy array image into pil image object\n",
                "    pil_image = Image.fromarray(current_frame)\n",
                "\n",
                "    # convert the pil image to draw object\n",
                "    d = ImageDraw.Draw(pil_image)\n",
                "\n",
                "    # loop for every face\n",
                "    index = 0\n",
                "\n",
                "    while index < len(face_landmarks_list):\n",
                "\n",
                "        # loop \n",
                "        for face_landmarks in face_landmarks_list:\n",
                "\n",
                "            # join each face landmark points\n",
                "            d.line(face_landmarks['chin'], fill=(255,255,255), width=2)\n",
                "            d.line(face_landmarks['left_eyebrow'], fill=(255,255,255), width=2)\n",
                "            d.line(face_landmarks['right_eyebrow'], fill=(255,255,255), width=2)\n",
                "            d.line(face_landmarks['nose_bridge'], fill=(255,255,255), width=2)\n",
                "            d.line(face_landmarks['nose_tip'], fill=(255,255,255), width=2)\n",
                "            d.line(face_landmarks['left_eye'], fill=(255,255,255), width=2)\n",
                "            d.line(face_landmarks['right_eye'], fill=(255,255,255), width=2)\n",
                "            d.line(face_landmarks['top_lip'], fill=(255,255,255), width=2)\n",
                "            d.line(face_landmarks['bottom_lip'], fill=(255,255,255), width=2)\n",
                "\n",
                "        index += 1\n",
                "\n",
                "    # convert PIL image to RGB to show in opencv window\n",
                "    rgb_image = pil_image.convert('RGB')\n",
                "    rgb_opencv_image = np.array(pil_image)\n",
                "\n",
                "    # convert RGB to BGR\n",
                "    bgr_opencv_image = cv2.cvtColor(rgb_opencv_image, cv2.COLOR_RGB2BGR)\n",
                "    bgr_opencv_image = bgr_opencv_image[:, :, ::-1].copy()\n",
                "\n",
                "    # showing the current face\n",
                "    cv2.imshow(\"Webcam video\", bgr_opencv_image)\n",
                "\n",
                "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
                "        break"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "webcam_video_stream.release()\n",
                "cv2.destroyAllWindows()"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit ('tensorflow1': conda)"
        },
        "interpreter": {
            "hash": "e68bb6439fcc53a682a5839c4f306372fff9a5c2c5cd5802c11b933a7d10d0f6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}